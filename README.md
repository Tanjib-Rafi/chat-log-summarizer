# Chat Log Summarizer

## ğŸ“˜ Overview

The **Chat Log Summarizer** is a Python-based tool that analyzes conversations between a user and an AI assistant. It extracts key metrics and generates concise summaries based on the dialogue.

Using **TF-IDF (Term Frequency-Inverse Document Frequency)**, it identifies the most relevant keywords in the chat, determines the main topics of discussion, and logs structured summaries.

---

## âœ¨ Features

- âœ… Parses structured chat logs (user and AI messages).
- ğŸ“Š Counts the number of exchanges (total, user, and AI).
- ğŸ§  Identifies top keywords using TF-IDF (including bigrams).
- ğŸ“ Generates a human-readable summary of each conversation.
- ğŸ“‚ Supports analyzing multiple chat log files in a single run.
- ğŸ” Automatically detects and skips empty or invalid chat logs.
- âš¡ Efficient keyword extraction with customizable parameters (e.g., `top_n` keywords).
- ğŸ›  Provides fallback mechanisms for cases where no keywords are extracted.

---

## ğŸ§± Requirements

This project requires Python **3.7+** and the following libraries:

- `numpy==2.2.6`
- `scikit-learn==1.6.1`
- `scipy==1.15.3`
- `joblib==1.5.0`
- `threadpoolctl==3.6.0`

---

## âš™ï¸ Installation & Setup

1. **Clone the repository** (or download the source files):

```
   git clone https://github.com/Tanjib-Rafi/chat-log-summarizer.git
```
```
   cd chat-log-summarizer
```

2. **Create a virtual environment**:

```
   python3 -m venv venv
```

```
source venv/bin/activate
```

3. **Install dependencies**:
```
pip install -r requirements.txt
```

4. **Run the script**:

```
python3 main.py
```


## ğŸ“‚ File Structure:

```
ğŸ“¦ chat-log-summarizer
â”œâ”€Â .gitignore
â”œâ”€Â README.md
â”œâ”€Â analyzer.py
â”œâ”€Â main.py
â”œâ”€Â parser.py
â”œâ”€Â requirements.txt
â””â”€Â sample_logs
Â Â Â â”œâ”€Â ecommerce.txt
Â Â Â â”œâ”€Â no_talk.txt
Â Â Â â”œâ”€Â no_user_no_ai.txt
Â Â Â â”œâ”€Â stock_price.txt
Â Â Â â””â”€Â war.txt
```


## âš™ï¸ Customization:

You can adjust keyword extraction sensitivity by modifying parameters like:

`top_n (number of keywords)`

`modifying unigrams and bigrams`

`min_df and max_df in the TF-IDF vectorizer`

`token_pattern to control which tokens are allowed (e.g., skip short words)`
